<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>ReadCV by imatge-upc</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">ReadCV</h1>
      <h2 class="project-tagline">Computer Vision Reading Group in Barcelona</h2>
      <a href="https://github.com/imatge-upc/readcv" class="btn">View on GitHub</a>
      <a href="https://github.com/imatge-upc/readcv/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/imatge-upc/readcv/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>A joint collaboration between:</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/readcv/master/logos/upc.jpg" alt="logo-upc" title="Universitat Politecnica de Catalunya"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/readcv/master/logos/ub.png" alt="logo-ub" title="Universitat de Barcelona"></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://imatge.upc.edu/web/">Image Processing Group at Universitat Politecnica de Catalunya (UPC)</a></td>
<td align="center"><a href="http://www.ub.edu/cvub/">Computer Vision Group at Universitat de Barcelona (UB)</a></td>
</tr>
</tbody>
</table>

<p>How do computers see ? How can they understand the contents of a scene captured by a camera ? The Computer Vision Reading Group addresses these problems, with special emphasis with <strong>deep learning</strong> and <strong>big data</strong> applications. </p>

<p>The reading group will meet at UPC and UB analyze a recent scientific publication. Each week, a different member of the group will prepare a set of slides to be shared and discussed with the attendees, who will have also previously read the paper. UPC-MET students will receive the corresponding ECTS according to their activity before and during each session. If you are interested in attending, send an e-mail to professor <a href="xavier.giro@upc.edu">Xavier Giró</a> from the <a href="http://www.imatge.upc.edu/">UPC Image Processing Group</a>.</p>

<p>Other reading groups with public listings: <a href="http://vision.cs.utexas.edu/readinggroup/">University of Texas</a>, <a href="http://www.cs.toronto.edu/%7Embrubake/visreading/">University of Toronto</a>, <a href="http://www.cs.ubc.ca/labs/lci/cvrg/">University of British Columbia</a>, <a href="https://www.facebook.com/groups/855857951197037/">Stanford University</a>, <a href="https://theberkeleyview.wordpress.com/">The Berkeley View</a>. </p>

<h3>
<a id="spring-2016" class="anchor" href="#spring-2016" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SPRING 2016</h3>

<h4>
<a id="wednesdays-from-1100am-to-1200pm" class="anchor" href="#wednesdays-from-1100am-to-1200pm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Wednesdays from 11:00am to 12:00pm</h4>

<h4>
<a id="-ub-plaça-universitat-maths-school-2nd-floor-room-t1" class="anchor" href="#-ub-pla%C3%A7a-universitat-maths-school-2nd-floor-room-t1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>@ <a href="http://www.maia.ub.edu/howtoarrive/index.html">UB Plaça Universitat, Maths school</a>, 2nd floor, Room T1</h4>

<ul>
<li><p>05/05/2016 (Maya Aghaei) Hyun Soo Park and Jianbo Sh. <a href="http://www.seas.upenn.edu/~hypar/SocialSaliencyPrediction_cameraready.pdf">Social Saliency Prediction</a>,  CVPR 2015.</p></li>
<li><p>13/04/2016 (Estefanía Tavalera) Tao Chen, Damian Borth, Trevor Darrell and Shih-Fu Chang. <a href="http://arxiv.org/pdf/1410.8586v1.pdf">DeepSentiBank: Visual sentiment concept classification with deep convolutional neural networks</a>,  arXiv preprint arXiv:1410.8586 (2014).</p></li>
<li><p>06/04/2016 (<a href="http://www.slideshare.net/AlejandroCartas/simultaneousdeeptransferacross-domainsandtasks">Slides by Alejandro Cartas</a>)Eric Tzeng, Judy Hoffman, Trevor Darrell, Kate Saenko. <a href="https://www.robots.ox.ac.uk/~vgg/rg/papers/Tzeng_ICCV2015.pdf">Simultaneous Deep Transfer Across Domains and Tasks</a>, ICCV 2015.</p></li>
<li><p>29/03/2016 (<a href="http://www.slideshare.net/nospotfer/convolutional-patch-representations-for-image-retrieval-an-unsupervised-approach">Slides by Gabriel de Oliveira</a>) Mattis Paulin, Julien Mairal, Matthijs Douze, Zaid Harchaoui, Florent Perronnin, Cordelia Schmid. <a href="http://arxiv.org/pdf/1603.00438v1.pdf">Convolutional Patch Representations for Image Retrieval: an Unsupervised Approach</a>, arxiv 2016. <a href="http://lear.inrialpes.fr/people/paulin/projects/RomePatches/">[Project page]</a></p></li>
<li><p>15/03/2016 (<a href="https://docs.google.com/presentation/d/1CItqjtAYa_OKVLs5BqqCzM8dEbCwkwit4Ooem_WJpY0/edit#slide=id.phttps://docs.google.com/presentation/d/1CItqjtAYa_OKVLs5BqqCzM8dEbCwkwit4Ooem_WJpY0/edit#slide=id.p">Slides by Marc Bolaños</a>) : Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba. <a href="http://cnnlocalization.csail.mit.edu/">Learning Deep Features for Discriminative Localization</a>, CVPR 2016.</p></li>
<li><p>08/03/2016 (<a href="https://slack-files.com/files-pri-safe/T0MCYTZ9U-F0T33MTK5/04_lrcn_bercea_ub.pdf?c=1458207772-2bf927d1c27aec9897947a459b8c91ea26f4a155">Slides by Cosmin Bercea</a>) : Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, Trevor Darrel. <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.html">Long-term Recurrent Convolutional Networks for Visual Recognition and Description</a>, CVPR 2015. <a href="https://github.com/BVLC/caffe/pull/2033">code</a></p></li>
<li><p>01/03/2016 (<a href="https://drive.google.com/drive/u/0/folders/0B60dHCK-AdwBfkxwQTM0czFSQ0lnUUxSWUUwUzk0QmFjMzNGYmMtWGtWb2VzNUE4MnY4eXM">Slides by Marc Carné</a>) :  Xiong, Bo, and Kristen Grauman. <a href="http://vision.cs.utexas.edu/projects/ego_snappoints/">"Detecting snap points in egocentric video with a web photo prior."</a>; In Computer Vision–ECCV 2014, pp. 282-298. Springer International Publishing, 2014.</p></li>
<li><p>23/02/016 (<a href="https://drive.google.com/file/d/0B_EUoF1fY47OcUZxYndDdjNMS0k/view?usp=sharing">Slides by Maya Aghaei:</a>) Yue-Hei Ng, Joe, Matthew Hausknecht, Sudheendra Vijayanarasimhan, Oriol Vinyals, Rajat Monga, and George Toderici.<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Ng_Beyond_Short_Snippets_2015_CVPR_paper.html"> "Beyond short snippets: Deep networks for video classification."</a> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4694-4702. 2015. <a href="https://youtu.be/oDRl3-X1KkI">[video]</a> <a href="http://googleresearch.blogspot.com.es/2015/04/beyond-short-snippets-deep-networks-for.html">[Google Research post]</a></p></li>
</ul>


<h4>
<a id="tuesdays-from-1100am-to-1200pm" class="anchor" href="#tuesdays-from-1100am-to-1200pm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Tuesdays from 11:00am to 12:00pm</h4>

<h4>
<a id="-upc-campus-nord-in-building-d5-room-003" class="anchor" href="#-upc-campus-nord-in-building-d5-room-003" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>@ <a href="https://imatge.upc.edu/web/contact">UPC Campus Nord in Building D5, Room 003</a>
</h4>

<ul>
<li><p>31/05/2016 (Santi Pascual): Xiong, Caiming, Stephen Merity, and Richard Socher. <a href="http://arxiv.org/abs/1603.01417">"Dynamic Memory Networks for Visual and Textual Question Answering."</a> arXiv preprint arXiv:1603.01417 (2016). <a href="https://news.ycombinator.com/item?id=11237125">[discussion]</a> <a href="http://www.nytimes.com/2016/03/07/technology/taking-baby-steps-toward-software-that-reasons-like-humans.html?_r=0">[Thew New York Times]</a></p></li>
<li><p>24/05/2016 (Elisa Sayrol): Srinivas S S Kruthiventi, Vennela Gudisa, Jaley H Dholakiya and R. Venkatesh Babu, "Saliency Unified: A Deep Architecture for simultaneous Eye Fixation Prediction and Salient Object Segmentation". In Proceedings of the IEEE International Conference on Computer Vision, 2016.</p></li>
<li><p>17/05/2016 (Andrea Ferri): Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Bin Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, and Wanli Ouyang, <a href="http://arxiv.org/pdf/1604.02532v1.pdf">T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos</a>, arXiv April 09 2016 [<a href="https://github.com/myfavouritekk/T-CNN">code</a>]</p></li>
<li><p>10/05/2016 (<a href="http://www.slideshare.net/xavigiro/visual7w-grounded-question-answering-in-images">Slides</a> and <a href="https://youtu.be/y4lM6_qfR1Q">Screencast</a> by Issey Masuda): Zhu, Yuke, Oliver Groth, Michael Bernstein, and Li Fei-Fei. <a href="http://web.stanford.edu/%7Eyukez/visual7w/index.html">"Visual7W: Grounded Question Answering in Images."</a> CVPR 2016.</p></li>
<li><p>03/05/2016 (<a href="http://www.slideshare.net/xavigiro/convolutional-features-for-instance-search">Slides</a> and <a href="https://vimeo.com/165478041">Video</a>): Mohedano E, Salvador A, McGuinness K, Giró-i-Nieto X, O'Connor N, Marqués F. Bags of Local Convolutional Features for Scalable Instance Search. In: ACM International Conference on Multimedia Retrieval (ICMR). New York City, NY; USA: 2016. </p></li>
<li><p>03/05/2016 (<a href="http://www.slideshare.net/xavigiro/convolutional-features-for-instance-search">Slides</a> and <a href="https://vimeo.com/165478041">Video</a>): Salvador A, Giró-i-Nieto X, Marqués F, Satoh S'ichi. <a href="http://imatge-upc.github.io/retrieval-2016-deepvision/">Faster R-CNN Features for Instance Search</a>. In: CVPR Workshop Deep Vision. Las Vegas, NV. USA. 2016</p></li>
<li><p>03/05/2016 (<a href="http://www.slideshare.net/xavigiro/deep-image-retrieval-learning-global-representations-for-image-search">Slides</a> and <a href="https://youtu.be/yT52xDML6ys">Screencast</a> by Albert Jiménez]: Gordo, Albert, Jon Almazan, Jerome Revaud, and Diane Larlus. <a href="http://arxiv.org/abs/1604.01325">"Deep Image Retrieval: Learning global representations for image search."</a> arXiv preprint arXiv:1604.01325 (2016).</p></li>
<li><p>26/04/2016 (<a href="http://www.slideshare.net/xavigiro/relative-attributes-61545128">Slides</a> by Dèlia Fernàndez): Parikh, Devi, and Kristen Grauman. <a href="http://www.cs.utexas.edu/%7Egrauman/papers/ParikhGrauman_ICCV2011_relative.pdf">"Relative attributes."</a> In Computer Vision (ICCV), 2011 IEEE International Conference on, pp. 503-510. IEEE, 2011.</p></li>
<li><p>12/04/2016 (<a href="https://www.youtube.com/watch?v=sM5pxgmAIiA">Screencast</a> and <a href="http://www.slideshare.net/xavigiro/describing-videos-by-exploiting-temporal-structure">Slides</a> by Alberto Montes): Yao, Li, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, and Aaron Courville. <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Yao_Describing_Videos_by_ICCV_2015_paper.html">"Describing videos by exploiting temporal structure."</a> In Proceedings of the IEEE International Conference on Computer Vision, pp. 4507-4515. 2015. <a href="http://gitxiv.com/posts/dKhP7eSaZKEfFmpzt/describing-videos-by-exploiting-temporal-structure">[code]</a></p></li>
<li><p>29/03/2016 (<a href="https://youtu.be/6NOQC_fl1hQ">Video</a> and <a href="http://www.slideshare.net/xavigiro/spatial-transformer-networks">Slides</a> by Victor Campos] Jaderberg, Max, Karen Simonyan, and Andrew Zisserman. <a href="http://papers.nips.cc/paper/5854-spatial-transformer-networks">Spatial transformer networks.</a> Advances in Neural Information Processing Systems 2015. </p></li>
</ul>

<p></p><ul>
<li>15/03/2016 (<a href="http://www.slideshare.net/xavigiro/you-only-look-once-unified-realtime-object-detection">Slides by Andrea Ferri)</a> Redmon, Joseph, Santosh Divvala, Ross Girshick, and Ali Farhadi. <a href="http://arxiv.org/abs/1506.02640">"You only look once: Unified, real-time object detection." </a><em>arXiv preprint arXiv:1506.02640</em> (2015). <a href="http://pjreddie.com/darknet/yolo/">[Project page]</a>
</li>
<li>01/03/2016 (<a href="http://www.slideshare.net/xavigiro/faster-rcnn-towards-realtime-object-detection-with-region-proposal-networks">Slides by Amaia Salvador</a>): Ren, S., He, K., Girshick, R. and Sun, J., 2015. <a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks">Faster R-CNN: Towards real-time object detection with region proposal networks</a>. In Advances in Neural Information Processing Systems (pp. 91-99). <a href="https://github.com/rbgirshick/py-faster-rcnn">[Python code]</a> <a href="https://github.com/ShaoqingRen/faster_rcnn">[Matlab code]</a>
</li>
<li>16/02/2016 (<a href="http://www.slideshare.net/xavigiro/active-object-localization-with-deep-reinforcement-learning">Slides by Míriam Bellver</a>): Caicedo, Juan C., and Svetlana Lazebnik. <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Caicedo_Active_Object_Localization_ICCV_2015_paper.html">"Active object localization with deep reinforcement learning."</a> In <em>Proceedings of the IEEE International Conference on Computer Vision</em>, pp. 2488-2496. 2015 <a href="https://www.reddit.com/r/MachineLearning/comments/3uqq0n/151106015_active_object_localization_with_deep/">[related Reddit]</a> <a href="http://www.slideshare.net/jirenjin5/2015-1030paperreadingsession">[slides from other reading group]</a>
</li>
</ul><div> </div><div> </div><div><strong>FALL 2015 (Tuesdays from 12:10pm to 1:10pm @ D5-003)</strong></div><div><ul>
<li>15-23/12/2015 (<a href="https://drive.google.com/file/d/0B60dHCK-AdwBN0E0MnVFR2dfTVU/view?usp=sharing">Slides by Marc Carné</a>): Aditya Khosla, Akhil S. Raju, Antonio Torralba and Aude Oliva, <a href="http://memorability.csail.mit.edu/">"</a><a href="http://memorability.csail.mit.edu/">Understanding and Predicting Image Memorability at a Large Scale"</a>. International Conference on Computer Vision (ICCV), 2015. </li>
<li>01/12/2015 (<a href="https://docs.google.com/presentation/d/1EgiHbY9a8g3I-SijuZ3GzC8eni4k-v8LKlzm_AIX_jc/edit?usp=sharing">Slides by Víctor Campos)</a>: Takuya Narihira, Damian Borth, Stella X. Yu, Karl Ni, Trevor Darrell, <a href="http://arxiv.org/pdf/1511.06838v1.pdf">"Mapping Images to Sentiment Adjective Noun Pairs with Factorized Neural Nets"</a>. </li>
<li>24/11/2015 (<a href="https://drive.google.com/file/d/0Bx7ke1oNC7PfdXNBeHFtUGcwUU0/view?usp=sharing">Slides by Alejandro Cartas</a>): Sun, Chen, Manohar Paluri, Ronan Collobert, Ram Nevatia, and Lubomir Bourdev. <a href="http://arxiv.org/abs/1511.03776">"ProNet: Learning to Propose Object-specific Boxes for Cascaded Neural Networks."</a> arXiv preprint arXiv:1511.03776 (2015).</li>
<li>17/11/2015 (<a href="https://docs.google.com/presentation/d/1y894l8FllKBoE6rNIAInCN6yhEO3ByK3pBfn3dozomU/edit?usp=sharing">Slides by Xavier Giró-i-Nieto</a>): Schroff, Florian, Dmitry Kalenichenko, and James Philbin. <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Schroff_FaceNet_A_Unified_2015_CVPR_paper.html">"FaceNet: A Unified Embedding for Face Recognition and Clustering."</a> Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. Implementation from <a href="https://github.com/cmusatyalab/openface">OpenFace</a>.</li>
<li>10/11/2015 (<a href="https://drive.google.com/file/d/0B60dHCK-AdwBc2kzU052dnNCQjA/view?usp=sharing">Slides by Elisa Sayrol</a>): Szegedy, Christian, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. <a href="http://research.google.com/pubs/pub43022.html">"Going Deeper With Convolutions."</a> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. 2015.</li>
<li>03/11/2015 (<a href="https://docs.google.com/presentation/d/1iQjxV6-u1JtrY2V11qs5TyVz7LX65fcnYHp2pwZqm94/edit?usp=sharing">Slides by Marc Bolaños</a>): Karpathy, Andrej, and Li Fei-Fei. <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">"Deep visual-semantic alignments for generating image descriptions." </a>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.</li>
<li>27/10/2015 (<a href="https://docs.google.com/presentation/d/1nbfOPxBwL9bwwynx-asTPcO8oKpgcUSK3wDdDWO0Z6s/edit?usp=sharing">Slides by Xavier Giró-i-Nieto</a>): Kruthiventi, Srinivas SS, Kumar Ayush, and R. Venkatesh Babu. <a href="http://arxiv.org/abs/1510.02927">"DeepFix: A Fully Convolutional Neural Network for predicting Human Eye Fixations."</a> arXiv preprint arXiv:1510.02927 (2015)</li>
<li>20/10/2015 (<a href="https://drive.google.com/file/d/0B60dHCK-AdwBU0N5VTUyT3NXYVE/view?usp=sharing">Slides by Albert Jiménez</a>): Castro, D., Hickson, S., Bettadapura, V., Thomaz, E., Abowd, G., Christensen, H., &amp; Essa, I. (2015, September). <a href="http://www.cc.gatech.edu/cpl/projects/dailyactivities/">Predicting daily activities from egocentric images using deep learning</a>. In Proceedings of the 2015 ACM International Symposium on Wearable Computers (pp. 75-82). ACM</li>
<li>13/10/2015 (<a href="https://docs.google.com/presentation/d/1Zi3qGOSHywDIc9tQL3OWiFKYAnbxXNTxnISUV24ituo/edit?usp=sharing">Slides by Miriam Bellver</a>): Hong, S., Noh, H., &amp; Han, B. (2015). <a href="http://cvlab.postech.ac.kr/research/decouplednet/">Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation</a>. arXiv preprint arXiv:1506.04924.</li>
<li>6/10/2015: CANCELLED</li>
<li>29/9/2015: CANCELLED</li>
<li>22/9/2015 (<a href="https://docs.google.com/presentation/d/1aIENfm4cJG53z4udGOW1t9TmUr_gb_IdZGsHeqD4P1k/edit?usp=sharing">Slides by Amaia Salvador</a>): Russakovsky, Olga, Li-Jia Li, and Li Fei-Fei. <a href="http://ai.stanford.edu/~olga/best_of_both_worlds.html">"Best of both worlds: human-machine collaboration for object annotation."</a> Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015</li>
<li>15/9/2015 (<a href="https://docs.google.com/presentation/d/18YbTfM0yjHklNaj_KXLSQ79fQvnwQaIP21d5Hi-llX4/edit?usp=sharing">Slides by Victor Campos</a>): Dosovitskiy, Alexey, Jost Tobias Springenberg, and Thomas Brox. <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf">"Learning to Generate Chairs With Convolutional Neural Networks."</a> Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. <a href="https://youtu.be/QCSW4isBDL0">[video]</a><br>
</li>
</ul></div><div> </div><div> </div><div><strong>SPRING 2015 (as DeepGPI)</strong></div><div><ul>
<li>02/07/2015 (<a href="https://docs.google.com/presentation/d/1zFBPew8sdZD9mL71MRIJwXphZOW9WVW8WOWEJAHCH2Q/edit?usp=sharing">Slides by Xavier Giró-i-Nieto</a>) Farabet, Clement, Camille Couprie, Laurent Najman, and Yann LeCun. <a href="http://www.clement.farabet.net/research.html#parsing">"Learning hierarchical features for scene labeling."</a> Pattern Analysis and Machine Intelligence, IEEE Transactions on 35, no. 8 (2013): 1915-1929</li>
<li>18/06/2015 (<a href="https://docs.google.com/presentation/d/1SOMTPqDA2QTSBeqInKFrkKGT7axtJOVjGWW0vygCvEI/edit?usp=sharing">Slides by Xavier Giró-i-Nieto</a>) Russakovsky, O., Bearman, A. L., Ferrari, V., &amp; Li, F. F. (2015). <a href="http://arxiv.org/abs/1506.02106">What's the point: Semantic segmentation with point supervision</a>. arXiv preprint arXiv:1506.02106</li>
<li>08/06/2015 (<a href="https://docs.google.com/presentation/d/13y66t5PezXQSlGCfvueIw1Z5kNFfauvau0Iy0JzaBwc/edit?usp=sharing">Slides by Amaia Salvador</a>) Girshick, R. (2015). <a href="http://arxiv.org/abs/1504.08083">Fast R-CNN</a>. arXiv preprint arXiv:1504.08083.</li>
<li>06/06/2015 (<a href="https://docs.google.com/presentation/d/1J8h19cuFvvSN310jCTyu2sjHXDWVaF-AF05wx0fjhGc/edit?usp=sharing">Slides by Amaia Salvador</a>) Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., &amp; Torralba, A. (2014). <a href="http://arxiv.org/abs/1412.6856">Object detectors emerge in deep scene CNNs</a>. arXiv preprint arXiv:1412.6856.</li>
<li>29/06/2015 (<a href="https://docs.google.com/presentation/d/1hynm-5VIa1u-1PxobyVRiOb43tjWqLjbxJOLPU08jlY/edit?usp=sharing">Slides by Eduard Fontdevila</a>) Hariharan, Arbelaez, Girshick, Malik, <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/shape/sds/">Simultaneous Detection and Segmentation</a> (ECCV 2014)</li>
<li>26/05/2015 (<a href="https://docs.google.com/presentation/d/1mEWbblfVCxb0_MjiI7iR5aUTCdvKsfp3uskq8NJNYQ0/edit?usp=sharing">Slides by Marc Bolaños</a>) Kuo, W., Hariharan, B., &amp; Malik, J. (2015). <a href="http://arxiv.org/abs/1505.02146">DeepBox: Learning Objectness with Convolutional Networks</a>. arXiv preprint arXiv:1505.02146.</li>
<li>21/05/2015 (<a href="https://docs.google.com/presentation/d/1Z8T6cnAnkkcc1GSvLD9tpOivJGXCOV85M3GHbtXzgbY/edit?usp=sharing">Slides by Xavier Giró-i-Nieto</a>) Hoffman, J., Guadarrama, S., Tzeng, E. S., Hu, R., Donahue, J., Girshick, R., ... &amp; Saenko, K. (2014). <a href="https://docs.google.com/presentation/d/1Z8T6cnAnkkcc1GSvLD9tpOivJGXCOV85M3GHbtXzgbY/edit?usp=sharing">LSDA: Large scale detection through adaptation</a>. In Advances in Neural Information Processing Systems (pp. 3536-3544).</li>
<li>28/04/2015 (<a href="https://docs.google.com/presentation/d/1fF7b0C7qj3US1tQZS0gP2ZiF5ltyjDv6BX4bGdwPJkQ/edit?usp=sharing">Slides by Eduard Fontdevila</a>) Chen, L. C., Papandreou, G., Kokkinos, I., Murphy, K., &amp; Yuille, A. L. (2014). <a href="https://docs.google.com/presentation/d/1fF7b0C7qj3US1tQZS0gP2ZiF5ltyjDv6BX4bGdwPJkQ/edit?usp=sharing">Semantic image segmentation with deep convolutional nets and fully connected CRFs</a>. arXiv preprint arXiv:1412.7062.</li>
<li>14/04/2015 (<a href="https://docs.google.com/presentation/d/1w3tFXfvcnVyHSZTHIFsqixbzOpsDLJIzjPR4vJVAPr0/edit?usp=sharing">Slides by Eduard Fontdevila</a>) Iandola, F., Moskewicz, M., Karayev, S., Girshick, R., Darrell, T., &amp; Keutzer, K. (2014). <a href="http://arxiv.org/abs/1404.1869">Densenet: Implementing efficient convnet descriptor pyramids</a>. arXiv preprint arXiv:1404.1869.</li>
<li>07/04/2015 (<a href="https://docs.google.com/presentation/d/18XRQvw193uPnMyPl-0LQqGyDqwnfFtzcn7BJsmoCMLo/edit?usp=sharing">Slides by Xavier Giró-i-Nieto</a>) Zeiler, Matthew D., and Rob Fergus. <a href="http://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf">"Visualizing and understanding convolutional networks."</a> In Computer Vision–ECCV 2014, pp. 818-833. Springer International Publishing, 2014</li>
<li>09/03/2015 (<a href="https://docs.google.com/presentation/d/1m9q052d_xbgv1oRHJlYgRdS5TuzQhKawV2pR54lF6VE/edit?usp=sharing">Slides by Amaia Salvador</a>) Babenko, Artem, et al. <a href="http://arxiv.org/abs/1404.1777">"Neural codes for image retrieval."</a> Computer Vision–ECCV 2014. Springer International Publishing, 2014. 584-599.</li>
<li>30/02/2015 (<a href="https://docs.google.com/presentation/d/1H9im4bbf3dC-iTmoOY-lLiHlZVTmQaPg9n9bOEIj8Tg/edit?usp=sharing">Slides by Junting Pan</a>) Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. <a href="http://arxiv.org/abs/1312.6034">"Deep inside convolutional networks: Visualising image classification models and saliency maps."</a> arXiv preprint arXiv:1312.6034 (2013)</li>
<li>23/02/2015 (<a href="https://docs.google.com/presentation/d/11CgZQ1cSuqRU06K-Kd6FGc2me2JufRbE2MQ0KeipyjM/edit?usp=sharing">Slides by Victor Campos</a>) You, Q., Luo, J., Jin, H., &amp; Yang, J. (2015, September). <a href="https://cs.rochester.edu/u/qyou/papers/sentiment_analysis_final.pdf">Robust image sentiment analysis using progressively trained and domain transferred deep networks</a>. In The Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI).</li>
<li>18/02/2015 (Slides by Victor Campos) Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., &amp; Fei-Fei, L. (2014, June). <a href="https://docs.google.com/presentation/d/1neslYvs4I35_4iXHfpkWOTn1Zw3xBs2PLki63zdMHYQ/edit?usp=sharing">Large-scale video classification with convolutional neural networks</a>. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on (pp. 1725-1732). IEEE</li>
</ul></div><div> </div>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/imatge-upc/readcv">ReadCV</a> is maintained by <a href="https://github.com/imatge-upc">imatge-upc</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
